{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copy this code to a databricks notebook to download the ORC\n",
    "file of Airlines data and convert it to Parquet file.\n",
    "\n",
    "This conversion is necessary before Pandas does not support\n",
    "reading ORC files.\n",
    "\"\"\"\n",
    "import cudf\n",
    "import numpy as np\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import gzip\n",
    "\n",
    "# ACTION REQUIRED - Set the DBFS path \n",
    "data_dir = \"/_dbfs_path/\" # DBFS path to the encompassing folder\n",
    "file_name = 'airline_20000000.orc' # Stores the name of the downloaded file\n",
    "orc_name = os.path.join(data_dir, file_name)\n",
    "\n",
    "def prepare_dataset():\n",
    "\n",
    "    input_cols = [\"Year\", \"Month\", \"DayofMonth\", \"DayofWeek\", \"CRSDepTime\", \"CRSArrTime\",\n",
    "                  \"UniqueCarrier\", \"FlightNum\", \"ActualElapsedTime\", \"Origin\", \"Dest\",\n",
    "                  \"Distance\", \"Diverted\"]\n",
    "\n",
    "    # Download URL\n",
    "    url = 'https://rapids-csp.s3-us-west-2.amazonaws.com/data/airline_20000000.orc'\n",
    "    \n",
    "    if os.path.isfile(orc_name):\n",
    "        print(f\" > File already exists. Ready to load at {orc_name}\")\n",
    "    else:\n",
    "        # Ensure folder exists\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        def data_progress_hook(block_number, read_size, total_filesize):\n",
    "            if (block_number % 1000) == 0:\n",
    "                print(\n",
    "                    f\" > percent complete: { 100 * ( block_number * read_size ) / total_filesize:.2f}\\r\",\n",
    "                    end=\"\",\n",
    "                )\n",
    "            return\n",
    "        urlretrieve(\n",
    "            url= url,\n",
    "            filename=orc_name,\n",
    "            reporthook=data_progress_hook,\n",
    "        )\n",
    "        \n",
    "        print(f\" > Download complete {url}\")\n",
    "        \n",
    "    dataset = cudf.read_orc(orc_name)\n",
    "\n",
    "    # encode categoricals as numeric\n",
    "    for col in dataset.select_dtypes([\"object\"]).columns:\n",
    "        dataset[col] = dataset[col].astype(\"category\").cat.codes.astype(np.int32)\n",
    "\n",
    "    # cast all columns to int32\n",
    "    for col in dataset.columns:\n",
    "        dataset[col] = dataset[col].astype(np.float32)  # needed for random forest\n",
    "\n",
    "    # put target/label column first [ classic XGBoost standard ]\n",
    "    output_cols = [\"ArrDelayBinary\"] + input_cols\n",
    "\n",
    "    dataset = dataset.reindex(columns=output_cols)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "df = prepare_dataset()\n",
    "\n",
    "parquet_name = os.path.join(data_dir, \"airline_20000000.parquet\")\n",
    "df.to_parquet(parquet_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "name": "acquire_data",
  "notebookId": 4348299065994525
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
